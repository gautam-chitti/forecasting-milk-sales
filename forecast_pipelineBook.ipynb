{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_FILE = 'milk_sales_datav1.csv'\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def parse_date(s):\n",
    "    \n",
    "    return pd.to_datetime(s, dayfirst=True, errors='coerce')\n",
    "\n",
    "def main():\n",
    "    \n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    \n",
    "    df.columns = [c.strip().title().replace('_',' ') for c in df.columns]\n",
    "\n",
    "    # Validate essential columns\n",
    "    required_cols = ['Date','Item Code','Route Code','Customer Code','Sales Quantity','Stales Quantity']\n",
    "    miss = [c for c in required_cols if c not in df.columns]\n",
    "    if miss:\n",
    "        raise ValueError(f'Missing columns: {miss}')\n",
    "\n",
    "  \n",
    "    df['Date'] = parse_date(df['Date'])\n",
    "    df['Sales Quantity'] = pd.to_numeric(df['Sales Quantity'], errors='coerce')\n",
    "    df['Stales Quantity'] = pd.to_numeric(df['Stales Quantity'], errors='coerce').fillna(0)\n",
    "\n",
    "    df = df.dropna(subset=['Date','Item Code','Customer Code','Sales Quantity']).copy()\n",
    "\n",
    "    # Net quantity\n",
    "    df['Net Quantity'] = (df['Sales Quantity'] - df['Stales Quantity']).clip(lower=0)\n",
    "\n",
    "    #  EDA\n",
    "    eda = {\n",
    "        'date_min': df['Date'].min(),\n",
    "        'date_max': df['Date'].max(),\n",
    "        'n_rows': len(df),\n",
    "        'n_customers': df['Customer Code'].nunique(),\n",
    "        'n_items': df['Item Code'].nunique(),\n",
    "        'n_routes': df['Route Code'].nunique(),\n",
    "        'total_sales_qty': df['Sales Quantity'].sum(),\n",
    "        'total_stales_qty': df['Stales Quantity'].sum(),\n",
    "        'total_net_qty': df['Net Quantity'].sum(),\n",
    "    }\n",
    "    pd.DataFrame({k:[v] for k,v in eda.items()}).to_csv('eda_summary.csv', index=False)\n",
    "\n",
    "    # Monthly aggregation\n",
    "    daily = (df.groupby(['Customer Code','Item Code','Date'], as_index=False)['Net Quantity']\n",
    "               .sum())\n",
    "    monthly = daily.copy()\n",
    "    monthly['MonthStart'] = monthly['Date'].values.astype('datetime64[M]')\n",
    "    monthly = (monthly.groupby(['Customer Code','Item Code','MonthStart'], as_index=False)['Net Quantity']\n",
    "                      .sum())\n",
    "\n",
    "    # Supervised frame\n",
    "    m = monthly.rename(columns={'MonthStart':'ds','Net Quantity':'y'})\n",
    "    m['year'] = m['ds'].dt.year\n",
    "    m['month'] = m['ds'].dt.month\n",
    "    m['quarter'] = m['ds'].dt.quarter\n",
    "\n",
    "    # Lag features \n",
    "    lag_k = [1,2,3,6,12]\n",
    "    chunks = []\n",
    "    for (cust,item), g in m.sort_values('ds').groupby(['Customer Code','Item Code']):\n",
    "        g = g.copy()\n",
    "        for k in lag_k:\n",
    "            g[f'lag_{k}'] = g['y'].shift(k)\n",
    "        g['rolling_3'] = g['y'].rolling(3).mean()\n",
    "        g['rolling_6'] = g['y'].rolling(6).mean()\n",
    "        chunks.append(g)\n",
    "    X = pd.concat(chunks, ignore_index=True)\n",
    "    lag_cols = [f'lag_{k}' for k in lag_k] + ['rolling_3','rolling_6']\n",
    "    X = X.dropna(subset=lag_cols).copy()\n",
    "\n",
    "    for col in ['Customer Code','Item Code']:\n",
    "        freq = X[col].value_counts(normalize=True)\n",
    "        X[f'{col}_freq'] = X[col].map(freq).astype(float)\n",
    "\n",
    "   \n",
    "    cutoff = X['ds'].max() - pd.offsets.MonthBegin(4)\n",
    "    train = X[X['ds'] < cutoff].copy()\n",
    "    valid = X[X['ds'] >= cutoff].copy()\n",
    "\n",
    "    features = lag_cols + ['year','month','quarter','Customer Code_freq','Item Code_freq']\n",
    "\n",
    "    model_name = None\n",
    "    model = None\n",
    "    try:\n",
    "        import lightgbm as lgb\n",
    "        model_name = 'lightgbm'\n",
    "        model = lgb.LGBMRegressor(\n",
    "            random_state=SEED, n_estimators=1200, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0, num_leaves=63\n",
    "        )\n",
    "    except Exception:\n",
    "        try:\n",
    "            from xgboost import XGBRegressor\n",
    "            model_name = 'xgboost'\n",
    "            model = XGBRegressor(\n",
    "                random_state=SEED, n_estimators=1200, learning_rate=0.05,\n",
    "                subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n",
    "                max_depth=8, tree_method='hist'\n",
    "            )\n",
    "        except Exception:\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            model_name = 'randomforest'\n",
    "            model = RandomForestRegressor(\n",
    "                random_state=SEED, n_estimators=600, n_jobs=-1, max_depth=None\n",
    "            )\n",
    "\n",
    "    from sklearn.metrics import r2_score\n",
    "    from sklearn.linear_model import Ridge\n",
    "\n",
    "    model.fit(train[features], train['y'])\n",
    "    valid_pred = model.predict(valid[features])\n",
    "    r2 = r2_score(valid['y'], valid_pred)\n",
    "\n",
    "    metrics = pd.DataFrame({'metric':['r2'], 'value':[r2], 'model':[model_name]})\n",
    "\n",
    "    if r2 < 0.5:\n",
    "        ridge = Ridge(alpha=1.0, random_state=SEED)\n",
    "        ridge.fit(train[features], train['y'])\n",
    "        valid_pred2 = ridge.predict(valid[features])\n",
    "        valid_blend = 0.7*valid_pred + 0.3*valid_pred2\n",
    "        r2_blend = r2_score(valid['y'], valid_blend)\n",
    "        metrics = pd.concat([metrics, pd.DataFrame({'metric':['r2_blend'], 'value':[r2_blend], 'model':[model_name + '+ridge']})], ignore_index=True)\n",
    "        if r2_blend > r2:\n",
    "            valid_pred = valid_blend\n",
    "            r2 = r2_blend\n",
    "\n",
    "    metrics.to_csv('validation_metrics.csv', index=False)\n",
    "\n",
    "    \n",
    "    series_scores = []\n",
    "    for (cust,item), g in X.groupby(['Customer Code','Item Code']):\n",
    "        g = g.sort_values('ds').copy()\n",
    "        cut = g['ds'].max() - pd.offsets.MonthBegin(4)\n",
    "        tr = g[g['ds'] < cut]\n",
    "        va = g[g['ds'] >= cut]\n",
    "        if len(tr) == 0 or len(va) == 0:\n",
    "            continue\n",
    "        yhat = model.predict(va[features])\n",
    "        s = r2_score(va['y'], yhat)\n",
    "        series_scores.append({'Customer Code':cust,'Item Code':item,'r2':s})\n",
    "    pd.DataFrame(series_scores).to_csv('validation_r2_by_series.csv', index=False)\n",
    "\n",
    "    \n",
    "    full = X.sort_values('ds').copy()\n",
    "    final_model = model\n",
    "    final_model.fit(full[features], full['y'])\n",
    "\n",
    "   \n",
    "    horizon = 12\n",
    "    future_rows = []\n",
    "\n",
    "    cust_freq_all = full['Customer Code'].value_counts(normalize=True)\n",
    "    item_freq_all = full['Item Code'].value_counts(normalize=True)\n",
    "\n",
    "    eng_hist = full[['Customer Code','Item Code','ds','y'] + lag_cols + ['year','month','quarter','Customer Code_freq','Item Code_freq']].copy()\n",
    "\n",
    "    for (cust,item), g in m.groupby(['Customer Code','Item Code']):\n",
    "        g = g.sort_values('ds').copy()\n",
    "        last_ds = g['ds'].max()\n",
    "\n",
    "        hist = eng_hist[(eng_hist['Customer Code']==cust) & (eng_hist['Item Code']==item)].sort_values('ds').copy()\n",
    "        recent = hist[['ds','y']].tail(12).copy()\n",
    "\n",
    "        for h in range(1, horizon+1):\n",
    "            next_ds = (last_ds + pd.offsets.MonthBegin(h))\n",
    "            feat = {}\n",
    "            feat['ds'] = pd.Timestamp(next_ds)\n",
    "            feat['year'] = feat['ds'].year\n",
    "            feat['month'] = feat['ds'].month\n",
    "            feat['quarter'] = feat['ds'].quarter\n",
    "\n",
    "            y_hist = recent.sort_values('ds')['y']\n",
    "            def last_k(k):\n",
    "                return y_hist.iloc[-k] if len(y_hist) >= k else np.nan\n",
    "\n",
    "            for k in [1,2,3,6,12]:\n",
    "                feat[f'lag_{k}'] = last_k(k)\n",
    "            feat['rolling_3'] = y_hist.iloc[-3:].mean() if len(y_hist) >= 3 else np.nan\n",
    "            feat['rolling_6'] = y_hist.iloc[-6:].mean() if len(y_hist) >= 6 else np.nan\n",
    "\n",
    "            feat['Customer Code_freq'] = float(cust_freq_all.get(cust, 0.0))\n",
    "            feat['Item Code_freq'] = float(item_freq_all.get(item, 0.0))\n",
    "\n",
    "          \n",
    "            if any(pd.isna([feat[c] for c in lag_cols])):\n",
    "                item_mean_by_month = m[m['Item Code']==item].groupby('month')['y'].mean()\n",
    "                fallback = item_mean_by_month.get(feat['month'], item_mean_by_month.mean())\n",
    "                for k in [1,2,3,6,12]:\n",
    "                    feat[f'lag_{k}'] = fallback\n",
    "                feat['rolling_3'] = fallback\n",
    "                feat['rolling_6'] = fallback\n",
    "\n",
    "            fvec = pd.DataFrame([feat])[features]\n",
    "            yhat = float(final_model.predict(fvec)[0])\n",
    "            recent = pd.concat([recent, pd.DataFrame({'ds':[feat['ds']], 'y':[yhat]})], ignore_index=True)\n",
    "            future_rows.append({'Customer Code':cust,'Item Code':item,'ds':feat['ds'],'yhat_monthly':yhat})\n",
    "\n",
    "    future = pd.DataFrame(future_rows)\n",
    "    future = future.sort_values(['Customer Code','Item Code','ds'])\n",
    "    # Aggregate to Q and Y\n",
    "    future['quarter'] = future['ds'].dt.to_period('Q')\n",
    "    future['year'] = future['ds'].dt.year\n",
    "    quarterly = (future.groupby(['Customer Code','Item Code','quarter'], as_index=False)['yhat_monthly']\n",
    "                       .sum().rename(columns={'yhat_monthly':'yhat_quarterly'}))\n",
    "    yearly = (future.groupby(['Customer Code','Item Code','year'], as_index=False)['yhat_monthly']\n",
    "                     .sum().rename(columns={'yhat_monthly':'yhat_yearly'}))\n",
    "\n",
    "    # Save\n",
    "    future.rename(columns={'ds':'MonthStart'}, inplace=True)\n",
    "    future.to_csv('forecast_monthly.csv', index=False)\n",
    "    quarterly.to_csv('forecast_quarterly.csv', index=False)\n",
    "    yearly.to_csv('forecast_yearly.csv', index=False)\n",
    "\n",
    "    \n",
    "    total_hist = (m.groupby('ds', as_index=False)['y'].sum()\n",
    "                    .rename(columns={'ds':'MonthStart','y':'Total_Net'})\n",
    "                    .sort_values('MonthStart'))\n",
    "    total_fore = (future.groupby('MonthStart', as_index=False)['yhat_monthly'].sum()\n",
    "                        .rename(columns={'yhat_monthly':'Total_Forecast'}))\n",
    "    total_hist.to_csv('viz_total_history.csv', index=False)\n",
    "    total_fore.to_csv('viz_total_forecast.csv', index=False)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        'r2_overall':[r2],\n",
    "        'model':[model_name],\n",
    "        'train_rows':[len(train)],\n",
    "        'valid_rows':[len(valid)],\n",
    "        'total_rows':[len(X)]\n",
    "    }).to_csv('run_summary.csv', index=False)\n",
    "\n",
    "    print('Done. Files: eda_summary.csv, validation_metrics.csv, run_summary.csv, forecast_monthly.csv, forecast_quarterly.csv, forecast_yearly.csv, viz_total_history.csv, viz_total_forecast.csv, validation_r2_by_series.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
